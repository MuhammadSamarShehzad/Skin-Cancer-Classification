{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010801,
     "end_time": "2023-04-08T14:54:29.68854",
     "exception": false,
     "start_time": "2023-04-08T14:54:29.677739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 1 : Importing Essetial Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:10.370836Z",
     "iopub.status.busy": "2024-12-30T14:02:10.370567Z",
     "iopub.status.idle": "2024-12-30T14:02:10.376955Z",
     "shell.execute_reply": "2024-12-30T14:02:10.376127Z",
     "shell.execute_reply.started": "2024-12-30T14:02:10.370811Z"
    },
    "papermill": {
     "duration": 9.222684,
     "end_time": "2023-04-08T14:54:38.921024",
     "exception": false,
     "start_time": "2023-04-08T14:54:29.69834",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:12.415164Z",
     "iopub.status.busy": "2024-12-30T14:02:12.414599Z",
     "iopub.status.idle": "2024-12-30T14:02:12.421223Z",
     "shell.execute_reply": "2024-12-30T14:02:12.420254Z",
     "shell.execute_reply.started": "2024-12-30T14:02:12.415132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00893,
     "end_time": "2023-04-08T14:54:38.939672",
     "exception": false,
     "start_time": "2023-04-08T14:54:38.930742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Step 2 : Importing Data and Creating a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:14.334068Z",
     "iopub.status.busy": "2024-12-30T14:02:14.333326Z",
     "iopub.status.idle": "2024-12-30T14:02:18.261130Z",
     "shell.execute_reply": "2024-12-30T14:02:18.260218Z",
     "shell.execute_reply.started": "2024-12-30T14:02:14.334032Z"
    },
    "papermill": {
     "duration": 4.466736,
     "end_time": "2023-04-08T14:54:43.416586",
     "exception": false,
     "start_time": "2023-04-08T14:54:38.94985",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2357 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path label\n",
       "0     /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "1     /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "2     /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "3     /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "4     /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "...                                                 ...   ...\n",
       "2352  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "2353  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "2354  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "2355  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "2356  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "\n",
       "[2357 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'\n",
    "test_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test'\n",
    "\n",
    "# Create dataframes\n",
    "train_df = pd.DataFrame(columns=['image_path', 'label'])\n",
    "test_df = pd.DataFrame(columns=['image_path', 'label'])\n",
    "\n",
    "# Add images paths and labels to dataframes\n",
    "for label, directory in e   numerate(os.listdir(train_dir)):\n",
    "    for filename in os.listdir(os.path.join(train_dir, directory)):\n",
    "        image_path = os.path.join(train_dir, directory, filename)\n",
    "        train_df = train_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n",
    "\n",
    "for label, directory in enumerate(os.listdir(test_dir)):\n",
    "    for filename in os.listdir(os.path.join(test_dir, directory)):\n",
    "        image_path = os.path.join(test_dir, directory, filename)\n",
    "        test_df = test_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n",
    "        \n",
    "# Combine train_df and test_df into one dataframe\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "del test_df,train_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:18.262860Z",
     "iopub.status.busy": "2024-12-30T14:02:18.262597Z",
     "iopub.status.idle": "2024-12-30T14:02:18.275299Z",
     "shell.execute_reply": "2024-12-30T14:02:18.274380Z",
     "shell.execute_reply.started": "2024-12-30T14:02:18.262836Z"
    },
    "papermill": {
     "duration": 0.371481,
     "end_time": "2023-04-08T15:03:42.849757",
     "exception": false,
     "start_time": "2023-04-08T15:03:42.478276",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>/kaggle/input/skin-cancer9-classesisic/Skin ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image_path label\n",
       "98    /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "1394  /kaggle/input/skin-cancer9-classesisic/Skin ca...     5\n",
       "940   /kaggle/input/skin-cancer9-classesisic/Skin ca...     2\n",
       "631   /kaggle/input/skin-cancer9-classesisic/Skin ca...     1\n",
       "1118  /kaggle/input/skin-cancer9-classesisic/Skin ca...     3\n",
       "2237  /kaggle/input/skin-cancer9-classesisic/Skin ca...     8\n",
       "1323  /kaggle/input/skin-cancer9-classesisic/Skin ca...     4\n",
       "1678  /kaggle/input/skin-cancer9-classesisic/Skin ca...     5\n",
       "84    /kaggle/input/skin-cancer9-classesisic/Skin ca...     0\n",
       "1255  /kaggle/input/skin-cancer9-classesisic/Skin ca...     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:20.061081Z",
     "iopub.status.busy": "2024-12-30T14:02:20.060349Z",
     "iopub.status.idle": "2024-12-30T14:02:20.068094Z",
     "shell.execute_reply": "2024-12-30T14:02:20.067220Z",
     "shell.execute_reply.started": "2024-12-30T14:02:20.061046Z"
    },
    "papermill": {
     "duration": 0.341888,
     "end_time": "2023-04-08T15:03:43.50365",
     "exception": false,
     "start_time": "2023-04-08T15:03:43.161762",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'pigmented benign keratosis',\n",
       " 1: 'melanoma',\n",
       " 2: 'vascular lesion',\n",
       " 3: 'actinic keratosis',\n",
       " 4: 'squamous cell carcinoma',\n",
       " 5: 'basal cell carcinoma',\n",
       " 6: 'seborrheic keratosis',\n",
       " 7: 'dermatofibroma',\n",
       " 8: 'nevus'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of directories in train_dir\n",
    "labels = os.listdir(train_dir)\n",
    "\n",
    "# Create label_map dictionary\n",
    "label_map = {i: label for i, label in enumerate(labels)}\n",
    "num_classes=len(label_map)\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:20.208591Z",
     "iopub.status.busy": "2024-12-30T14:02:20.207985Z",
     "iopub.status.idle": "2024-12-30T14:02:20.228519Z",
     "shell.execute_reply": "2024-12-30T14:02:20.227675Z",
     "shell.execute_reply.started": "2024-12-30T14:02:20.208564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "max_images_per_class = 2500\n",
    "\n",
    "# Group by label column and take first max_images_per_class rows for each group\n",
    "df = df.groupby(\"label\").apply(lambda x: x.head(max_images_per_class)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:23.104508Z",
     "iopub.status.busy": "2024-12-30T14:02:23.103793Z",
     "iopub.status.idle": "2024-12-30T14:02:23.480156Z",
     "shell.execute_reply": "2024-12-30T14:02:23.479131Z",
     "shell.execute_reply.started": "2024-12-30T14:02:23.104474Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Allow gpu usage\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth = True\n",
    "except Exception as ex:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:23.482348Z",
     "iopub.status.busy": "2024-12-30T14:02:23.481941Z",
     "iopub.status.idle": "2024-12-30T14:02:23.494015Z",
     "shell.execute_reply": "2024-12-30T14:02:23.493257Z",
     "shell.execute_reply.started": "2024-12-30T14:02:23.482320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Get the number of CPU cores available\n",
    "max_workers = multiprocessing.cpu_count()\n",
    "max_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:25.095044Z",
     "iopub.status.busy": "2024-12-30T14:02:25.094453Z",
     "iopub.status.idle": "2024-12-30T14:02:53.707933Z",
     "shell.execute_reply": "2024-12-30T14:02:53.706894Z",
     "shell.execute_reply.started": "2024-12-30T14:02:25.095010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# Define a function to resize image arrays\n",
    "def resize_image_array(image_path):\n",
    "    return np.asarray(Image.open(image_path).resize((100,75)))\n",
    "\n",
    "# Use concurrent.futures to parallelize the resizing process\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    # Use executor.map to apply the function to each image path in the DataFrame\n",
    "    image_arrays = list(executor.map(resize_image_array, df['image_path'].tolist()))\n",
    "\n",
    "# Add the resized image arrays to the DataFrame\n",
    "df['image'] = image_arrays\n",
    "del image_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:56.527186Z",
     "iopub.status.busy": "2024-12-30T14:02:56.526511Z",
     "iopub.status.idle": "2024-12-30T14:02:56.532766Z",
     "shell.execute_reply": "2024-12-30T14:02:56.531607Z",
     "shell.execute_reply.started": "2024-12-30T14:02:56.527150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator object with the desired transformations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:02:56.604340Z",
     "iopub.status.busy": "2024-12-30T14:02:56.604005Z",
     "iopub.status.idle": "2024-12-30T14:04:21.192899Z",
     "shell.execute_reply": "2024-12-30T14:04:21.191778Z",
     "shell.execute_reply.started": "2024-12-30T14:02:56.604316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an empty dataframe to store the augmented images\n",
    "augmented_df = pd.DataFrame(columns=['image_path', 'label', 'image'])\n",
    "\n",
    "# Loop through each class label and generate additional images if needed\n",
    "for class_label in df['label'].unique():\n",
    "    # Get the image arrays for the current class\n",
    "    image_arrays = df.loc[df['label'] == class_label, 'image'].values\n",
    "    \n",
    "    # Calculate the number of additional images needed for the current class\n",
    "    num_images_needed = max_images_per_class - len(image_arrays)\n",
    "    \n",
    "    # Generate augmented images for the current class\n",
    "    if num_images_needed > 0:\n",
    "        # Select a random subset of the original images\n",
    "        selected_images = np.random.choice(image_arrays, size=num_images_needed)\n",
    "        \n",
    "        # Apply transformations to the selected images and add them to the augmented dataframe\n",
    "        for image_array in selected_images:\n",
    "            # Reshape the image array to a 4D tensor with a batch size of 1\n",
    "            image_tensor = np.expand_dims(image_array, axis=0)\n",
    "            \n",
    "            # Generate the augmented images\n",
    "            augmented_images = datagen.flow(image_tensor, batch_size=1)\n",
    "            \n",
    "            # Extract the augmented image arrays and add them to the augmented dataframe\n",
    "            for i in range(augmented_images.n):\n",
    "                augmented_image_array = augmented_images.next()[0].astype('uint8')\n",
    "                augmented_df = augmented_df.append({'image_path': None, 'label': class_label, 'image': augmented_image_array}, ignore_index=True)\n",
    "    \n",
    "    # Add the original images for the current class to the augmented dataframe\n",
    "    original_images_df = df.loc[df['label'] == class_label, ['image_path', 'label', 'image']]\n",
    "    augmented_df = augmented_df.append(original_images_df, ignore_index=True)\n",
    "\n",
    "# Group the augmented dataframe by the 'label' column and filter out extra images\n",
    "df = augmented_df.groupby('label').head(max_images_per_class)\n",
    "\n",
    "del augmented_df\n",
    "\n",
    "# Use the augmented dataframe for further processing\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:24.821838Z",
     "iopub.status.busy": "2024-12-30T14:04:24.820947Z",
     "iopub.status.idle": "2024-12-30T14:04:24.832952Z",
     "shell.execute_reply": "2024-12-30T14:04:24.831977Z",
     "shell.execute_reply.started": "2024-12-30T14:04:24.821801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "------------------------------------------------------------\n",
      "Class Label     Class Name                     Count     \n",
      "------------------------------------------------------------\n",
      "0               pigmented benign keratosis     2500      \n",
      "1               melanoma                       2500      \n",
      "2               vascular lesion                2500      \n",
      "3               actinic keratosis              2500      \n",
      "4               squamous cell carcinoma        2500      \n",
      "5               basal cell carcinoma           2500      \n",
      "6               seborrheic keratosis           2500      \n",
      "7               dermatofibroma                 2500      \n",
      "8               nevus                          2500      \n",
      "------------------------------------------------------------\n",
      "Total                                         22500     \n"
     ]
    }
   ],
   "source": [
    "# Count the number of images in each class\n",
    "class_counts = df['label'].value_counts().sort_index()\n",
    "\n",
    "# Print the number of images in each class\n",
    "print(\"Dataset Summary\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\n",
    "print(\"-\" * 60)\n",
    "for class_label, class_name in label_map.items():\n",
    "    count = class_counts[class_label]\n",
    "    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total':<45} {sum(class_counts):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:25.212475Z",
     "iopub.status.busy": "2024-12-30T14:04:25.211798Z",
     "iopub.status.idle": "2024-12-30T14:04:25.218012Z",
     "shell.execute_reply": "2024-12-30T14:04:25.217047Z",
     "shell.execute_reply.started": "2024-12-30T14:04:25.212444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = df.drop(columns=['label','image_path'],axis=1)\n",
    "target = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:27.165123Z",
     "iopub.status.busy": "2024-12-30T14:04:27.164474Z",
     "iopub.status.idle": "2024-12-30T14:04:27.172897Z",
     "shell.execute_reply": "2024-12-30T14:04:27.172212Z",
     "shell.execute_reply.started": "2024-12-30T14:04:27.165090Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:27.315696Z",
     "iopub.status.busy": "2024-12-30T14:04:27.315417Z",
     "iopub.status.idle": "2024-12-30T14:04:31.600930Z",
     "shell.execute_reply": "2024-12-30T14:04:31.599898Z",
     "shell.execute_reply.started": "2024-12-30T14:04:27.315671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train['image'].tolist())\n",
    "x_test = np.asarray(x_test['image'].tolist())\n",
    "\n",
    "x_train_mean = np.mean(x_train)\n",
    "x_train_std = np.std(x_train)\n",
    "x_test_mean = np.mean(x_test)\n",
    "x_test_std = np.std(x_test)\n",
    "\n",
    "x_train = (x_train - x_train_mean)/x_train_std\n",
    "x_test = (x_test - x_test_mean)/x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:33.185550Z",
     "iopub.status.busy": "2024-12-30T14:04:33.185154Z",
     "iopub.status.idle": "2024-12-30T14:04:33.191535Z",
     "shell.execute_reply": "2024-12-30T14:04:33.190556Z",
     "shell.execute_reply.started": "2024-12-30T14:04:33.185515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on the labels\n",
    "y_train = to_categorical(y_train,num_classes = num_classes)\n",
    "y_test = to_categorical(y_test,num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:33.339637Z",
     "iopub.status.busy": "2024-12-30T14:04:33.339085Z",
     "iopub.status.idle": "2024-12-30T14:04:34.291713Z",
     "shell.execute_reply": "2024-12-30T14:04:34.290620Z",
     "shell.execute_reply.started": "2024-12-30T14:04:33.339608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:35.770320Z",
     "iopub.status.busy": "2024-12-30T14:04:35.769717Z",
     "iopub.status.idle": "2024-12-30T14:04:35.775116Z",
     "shell.execute_reply": "2024-12-30T14:04:35.774176Z",
     "shell.execute_reply.started": "2024-12-30T14:04:35.770285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\n",
    "x_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\n",
    "x_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:36.002819Z",
     "iopub.status.busy": "2024-12-30T14:04:36.002140Z",
     "iopub.status.idle": "2024-12-30T14:04:36.006887Z",
     "shell.execute_reply": "2024-12-30T14:04:36.006027Z",
     "shell.execute_reply.started": "2024-12-30T14:04:36.002793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_validate = y_validate.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:37.968773Z",
     "iopub.status.busy": "2024-12-30T14:04:37.967745Z",
     "iopub.status.idle": "2024-12-30T14:04:37.977806Z",
     "shell.execute_reply": "2024-12-30T14:04:37.976723Z",
     "shell.execute_reply.started": "2024-12-30T14:04:37.968723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "------------------------------------------------------------------------------------------\n",
      "Class Label     Class Name                     Train      Validation   Test       Total     \n",
      "------------------------------------------------------------------------------------------\n",
      "0               pigmented benign keratosis     1607       405          488        2500      \n",
      "1               melanoma                       1619       390          491        2500      \n",
      "2               vascular lesion                1571       439          490        2500      \n",
      "3               actinic keratosis              1617       394          489        2500      \n",
      "4               squamous cell carcinoma        1569       386          545        2500      \n",
      "5               basal cell carcinoma           1625       382          493        2500      \n",
      "6               seborrheic keratosis           1616       393          491        2500      \n",
      "7               dermatofibroma                 1591       400          509        2500      \n",
      "8               nevus                          1585       411          504        2500      \n",
      "------------------------------------------------------------------------------------------\n",
      "Total                                          14400      3600         4500       22500     \n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of images in each class for train, validation, and test datasets\n",
    "train_counts = np.sum(y_train, axis=0)\n",
    "val_counts = np.sum(y_validate, axis=0)\n",
    "test_counts = np.sum(y_test, axis=0)\n",
    "\n",
    "# Print the number of images in each class for train, validation, and test datasets\n",
    "print(\"Dataset Summary\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Class Label':<15} {'Class Name':<30} {'Train':<10} {'Validation':<12} {'Test':<10} {'Total':<10}\")\n",
    "print(\"-\" * 90)\n",
    "for class_label, class_name in label_map.items():\n",
    "    train_num = int(train_counts[class_label])\n",
    "    val_num = int(val_counts[class_label])\n",
    "    test_num = int(test_counts[class_label])\n",
    "    total_num = train_num + val_num + test_num\n",
    "    print(f\"{class_label:<15} {class_name:<30} {train_num:<10} {val_num:<12} {test_num:<10} {total_num:<10}\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Total':<46} {len(y_train):<10} {len(y_validate):<12} {len(y_test):<10} {len(y_train) + len(y_validate) + len(y_test):<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:41.199746Z",
     "iopub.status.busy": "2024-12-30T14:04:41.199025Z",
     "iopub.status.idle": "2024-12-30T14:04:41.205696Z",
     "shell.execute_reply": "2024-12-30T14:04:41.204839Z",
     "shell.execute_reply.started": "2024-12-30T14:04:41.199711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 100, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = df['image'][0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:41.279767Z",
     "iopub.status.busy": "2024-12-30T14:04:41.279092Z",
     "iopub.status.idle": "2024-12-30T14:04:52.616075Z",
     "shell.execute_reply": "2024-12-30T14:04:52.614941Z",
     "shell.execute_reply.started": "2024-12-30T14:04:41.279740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74836368/74836368 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet201 (Functional)    (None, 2, 3, 1920)        18321984  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 11520)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               5898752   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 4617      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,225,353\n",
      "Trainable params: 23,996,297\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "# DenseNet201\n",
    "model = Sequential()\n",
    "model.add(DenseNet201(include_top=False, weights='imagenet', input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))  # Add a Dropout layer with a dropout rate of 0.5\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:04:52.618583Z",
     "iopub.status.busy": "2024-12-30T14:04:52.618139Z",
     "iopub.status.idle": "2024-12-30T14:04:52.645538Z",
     "shell.execute_reply": "2024-12-30T14:04:52.644613Z",
     "shell.execute_reply.started": "2024-12-30T14:04:52.618541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "from keras.optimizers import SGD\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T14:05:03.032801Z",
     "iopub.status.busy": "2024-12-30T14:05:03.031996Z",
     "iopub.status.idle": "2024-12-30T14:49:15.453559Z",
     "shell.execute_reply": "2024-12-30T14:49:15.452757Z",
     "shell.execute_reply.started": "2024-12-30T14:05:03.032766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "450/450 [==============================] - 88s 125ms/step - loss: 1.1797 - accuracy: 0.5807 - val_loss: 0.6433 - val_accuracy: 0.7581 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "450/450 [==============================] - 53s 118ms/step - loss: 0.5441 - accuracy: 0.7969 - val_loss: 0.4700 - val_accuracy: 0.8256 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.3527 - accuracy: 0.8646 - val_loss: 0.4110 - val_accuracy: 0.8528 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "450/450 [==============================] - 52s 117ms/step - loss: 0.2577 - accuracy: 0.9056 - val_loss: 0.3334 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.1933 - accuracy: 0.9265 - val_loss: 0.3463 - val_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.1736 - accuracy: 0.9333 - val_loss: 0.3042 - val_accuracy: 0.8972 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.1471 - accuracy: 0.9455 - val_loss: 0.3994 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.1270 - accuracy: 0.9498 - val_loss: 0.3271 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.1067 - accuracy: 0.9606 - val_loss: 0.3771 - val_accuracy: 0.8931 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.3174 - val_accuracy: 0.9078 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0819 - accuracy: 0.9693 - val_loss: 0.3872 - val_accuracy: 0.8831 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0836 - accuracy: 0.9698 - val_loss: 0.3947 - val_accuracy: 0.8939 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0713 - accuracy: 0.9728 - val_loss: 0.3749 - val_accuracy: 0.8994 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0527 - accuracy: 0.9811 - val_loss: 0.3301 - val_accuracy: 0.9158 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0480 - accuracy: 0.9824 - val_loss: 0.3658 - val_accuracy: 0.8969 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0456 - accuracy: 0.9827 - val_loss: 0.4203 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0458 - accuracy: 0.9823 - val_loss: 0.3956 - val_accuracy: 0.9039 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0448 - accuracy: 0.9832 - val_loss: 0.3902 - val_accuracy: 0.9086 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0372 - accuracy: 0.9851 - val_loss: 0.4413 - val_accuracy: 0.9025 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0396 - accuracy: 0.9850 - val_loss: 0.4153 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0356 - accuracy: 0.9865 - val_loss: 0.4336 - val_accuracy: 0.9003 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0370 - accuracy: 0.9859 - val_loss: 0.4366 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0372 - accuracy: 0.9860 - val_loss: 0.4301 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0376 - accuracy: 0.9843 - val_loss: 0.4091 - val_accuracy: 0.9064 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0358 - accuracy: 0.9856 - val_loss: 0.4244 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0331 - accuracy: 0.9866 - val_loss: 0.5229 - val_accuracy: 0.8914 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0339 - accuracy: 0.9865 - val_loss: 0.4913 - val_accuracy: 0.9008 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0293 - accuracy: 0.9884 - val_loss: 0.4921 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0225 - accuracy: 0.9905 - val_loss: 0.4707 - val_accuracy: 0.9092 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0227 - accuracy: 0.9897 - val_loss: 0.4755 - val_accuracy: 0.9097 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0261 - accuracy: 0.9890 - val_loss: 0.4834 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0220 - accuracy: 0.9894 - val_loss: 0.4793 - val_accuracy: 0.9064 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0223 - accuracy: 0.9900 - val_loss: 0.5569 - val_accuracy: 0.9008 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0243 - accuracy: 0.9889 - val_loss: 0.5175 - val_accuracy: 0.9056 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0213 - accuracy: 0.9908 - val_loss: 0.5133 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0178 - accuracy: 0.9915 - val_loss: 0.5360 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0210 - accuracy: 0.9895 - val_loss: 0.5329 - val_accuracy: 0.9131 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0196 - accuracy: 0.9906 - val_loss: 0.6338 - val_accuracy: 0.9022 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0170 - accuracy: 0.9915 - val_loss: 0.5171 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0184 - accuracy: 0.9909 - val_loss: 0.5287 - val_accuracy: 0.9119 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.5144 - val_accuracy: 0.9075 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0149 - accuracy: 0.9924 - val_loss: 0.5225 - val_accuracy: 0.9103 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0155 - accuracy: 0.9919 - val_loss: 0.5197 - val_accuracy: 0.9153 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0175 - accuracy: 0.9917 - val_loss: 0.5382 - val_accuracy: 0.9197 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0165 - accuracy: 0.9917 - val_loss: 0.5277 - val_accuracy: 0.9114 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0188 - accuracy: 0.9907 - val_loss: 0.5550 - val_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0161 - accuracy: 0.9924 - val_loss: 0.5513 - val_accuracy: 0.9131 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0156 - accuracy: 0.9918 - val_loss: 0.4998 - val_accuracy: 0.9136 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0159 - accuracy: 0.9921 - val_loss: 0.5295 - val_accuracy: 0.9056 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "450/450 [==============================] - 52s 116ms/step - loss: 0.0185 - accuracy: 0.9915 - val_loss: 0.5045 - val_accuracy: 0.9131 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "epochs = 50\n",
    "batch_size=32\n",
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(x_validate,y_validate),\n",
    "                    callbacks=learning_rate_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T15:26:15.972069Z",
     "iopub.status.busy": "2024-12-30T15:26:15.971717Z",
     "iopub.status.idle": "2024-12-30T15:26:17.591404Z",
     "shell.execute_reply": "2024-12-30T15:26:17.590655Z",
     "shell.execute_reply.started": "2024-12-30T15:26:15.972038Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/kaggle/working/skin_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.move('/kaggle/working/skin_disease_model.h5', '/path/to/your/local/directory/skin_disease_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = load_model('skin_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the label map\n",
    "label_map = {\n",
    "    0: 'pigmented benign keratosis',\n",
    "    1: 'melanoma',\n",
    "    2: 'vascular lesion',\n",
    "    3: 'actinic keratosis',\n",
    "    4: 'squamous cell carcinoma',\n",
    "    5: 'basal cell carcinoma',\n",
    "    6: 'seborrheic keratosis',\n",
    "    7: 'dermatofibroma',\n",
    "    8: 'nevus'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the image\n",
    "image_path = r'E:\\FYP Content\\New\\Skin Cancer\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\\squamous cell carcinoma\\ISIC_0011593.jpg'\n",
    "\n",
    "# Load the image and preprocess it\n",
    "img = image.load_img(image_path, target_size=(75, 100))  # Correct order: height=75px, width=100px\n",
    "img_array = image.img_to_array(img)  # Convert image to array\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Normalize the image as per the training data preprocessing\n",
    "img_array = (img_array - np.mean(img_array)) / np.std(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted Class: squamous cell carcinoma\n"
     ]
    }
   ],
   "source": [
    "# Predict the class\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Map the predicted class index to the class label\n",
    "predicted_label = label_map[predicted_class[0]]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 319080,
     "sourceId": 643971,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30461,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
